\chapter{Conclusion}
\label{cha:conclusion}

% \Autosectionref{sec:contributions} will summarize the contributions of this thesis and the significance of these, and discuss the contributions in terms of the goals and research questions formulated in the \nameref{cha:introduction}. \Autosectionref{sec:future-work} will highlight potential areas for future work that were not investigated in this thesis but are considered crucial for optimizing the performance of \acrshort{acr:llm}-based \acrshort{acr:gis} agents.

% \section{Contributions}
% \label{sec:contributions}

\begin{comment}
What are the main contributions made to the field?
How significant are these contributions?
Also discuss the contributions in terms of the goals and research questions formulated in the Introduction.

The contributions section will normally contain everything that you address in the abstract, but in an extended form and quite possibly additional issues that cannot be included in the abstract.
An obvious difference is that when the reader has come this far in the text, she/he should be quite familiar with the work, but while reading the abstract they will have little to no knowledge of the work.

The section ``Contributions'' in Chapter~\ref{cha:introduction} differs from this one in that the former is just a list of the main bits, while this section should explain them in more detail.
However, basically the same items should appear in both sections.
\end{comment}

This thesis has shown the viability of using \gls{acr:llm} technology to create autonomous agents aimed at \acrshort{acr:gis} analysis. \textit{GeoGPT}, the proposed solution, shows through a new \acrshort{acr:gis} benchmark containing question and answer pairs for common \acrshort{acr:gis} tasks, that it is able to utilize the logical reasoning and code generation abilities of modern \glspl{acr:llm} like \acrshort{acr:gpt}-4 to solve a wide range of such tasks. The user interacts with GeoGPT through a webpage that consists of a chat interface resembling that of OpenAI's ChatGPT, and a web map where results from analyses can be displayed. The user can type geospatial questions into the chat interface, which GeoGPT will attempt answer to through text and/or by adding geometries to the map. GeoGPT relies heavily on \textit{function calling}. This is a way of giving function/tool definitions to an \acrshort{acr:llm}, essentially enabling it to \textit{invoke} these external tools, which run code created by the developer, by specifying the name of the tool and suitable parameters that will be passed to it.

Featuring three different agent types, GeoGPT shows that it can manipulate geospatial data in different ways. One agent accesses data directly from a PostGIS database, another agent accesses data through an \acrshort{acr:ogc} \acrshort{acr:api} Features server that resides on top of this PostGIS database, and the final agent accesses data through shapefiles in GeoGPT's local environment. The agents have different sets of tools that allow them to work with their data. Included in the \acrshort{acr:sql} agent's collection of tools, is a tool that takes a string of \acrshort{acr:sql} code that will be run against the database, thus enabling the agent to perform geospatial analyses. The \acrshort{acr:ogc} \acrshort{acr:api} Features agent and the agent with access to shapefiles, both have access to a similar tool that allows them to run Python code. Other tools include tools to list database table and collections \acrshort{acr:ogc} \acrshort{acr:api} Features server, and a tool to geometries to the web map.

% In addition to this, the \acrshort{acr:ogc} \acrshort{acr:api} Features agent has access to functions/tools work against the \acrshort{acr:ogc} \acrshort{acr:api} Features endpoint.

Two sets of experiments were conducted. The first revolves around the \acrshort{acr:gis} becnhmark, comparing the three agent types to see which is best at solving common \acrshort{acr:gis}-related tasks. Results from this experiment show that the \acrshort{acr:sql} agent outperforms the other two, with a success rate of 69.4\% compared to 38.9\% for each of the others.

The second set of experiments evaluates the importance of the quality of the problem question from the user. Questions were formulated in two different ways: a simple formulation, resembling a user with little \acrshort{acr:gis} experience, and a more accurate and detailed formulation, resembling a user with extensive \acrshort{acr:gis} experience. The results from the experiment show that providing GeoGPT with a higher quality (more accurate and detailed) initial problem formulation greatly increases the likelyhood of the system to produce a successful outcome, suggesting that a user's \acrshort{acr:gis} experience is still very valuable, even as we face a reality where highly sophisticated \glspl{acr:llm} can be used to automate away numerous technical tasks.
