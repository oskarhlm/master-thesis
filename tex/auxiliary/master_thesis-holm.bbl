% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{apa/global//global/global}
    \entry{chaseLangChain2022}{misc}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=c6b41fd745709d65ec7ab70864b8b466}{%
           family={Chase},
           familyi={C\bibinitperiod},
           given={Harrison},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{c6b41fd745709d65ec7ab70864b8b466}
      \strng{fullhash}{c6b41fd745709d65ec7ab70864b8b466}
      \strng{bibnamehash}{c6b41fd745709d65ec7ab70864b8b466}
      \strng{authorbibnamehash}{c6b41fd745709d65ec7ab70864b8b466}
      \strng{authornamehash}{c6b41fd745709d65ec7ab70864b8b466}
      \strng{authorfullhash}{c6b41fd745709d65ec7ab70864b8b466}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{⚡ Building applications with LLMs through composability ⚡}
      \field{month}{10}
      \field{title}{{{LangChain}}}
      \field{urlday}{5}
      \field{urlmonth}{10}
      \field{urlyear}{2023}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://github.com/langchain-ai/langchain
      \endverb
      \verb{url}
      \verb https://github.com/langchain-ai/langchain
      \endverb
    \endentry
    \entry{eletiFunctionCallingOther2023}{misc}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=03285595b2a21f9031cc188e80917e56}{%
           family={Eleti},
           familyi={E\bibinitperiod},
           given={Atty},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e5decf4e915d76af51b79287d4751e1}{%
           family={Harris},
           familyi={H\bibinitperiod},
           given={Jeff},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8cfa1b83e7a1a06a25480667bca5be30}{%
           family={Kilpatrick},
           familyi={K\bibinitperiod},
           given={Logan},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{5adffc21b072dfdd98bac4f782b2d4da}
      \strng{fullhash}{00695b5a0fb3e1d43267162449b2bccf}
      \strng{bibnamehash}{00695b5a0fb3e1d43267162449b2bccf}
      \strng{authorbibnamehash}{00695b5a0fb3e1d43267162449b2bccf}
      \strng{authornamehash}{5adffc21b072dfdd98bac4f782b2d4da}
      \strng{authorfullhash}{00695b5a0fb3e1d43267162449b2bccf}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We're announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.}
      \field{langid}{american}
      \field{month}{6}
      \field{title}{Function Calling and Other {{API}} Updates}
      \field{urlday}{10}
      \field{urlmonth}{3}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{urldateera}{ce}
      \verb{file}
      \verb C:\Users\oskar\Zotero\storage\6X3BUD24\function-calling-and-other-api-updates.html
      \endverb
      \verb{urlraw}
      \verb https://openai.com/blog/function-calling-and-other-api-updates
      \endverb
      \verb{url}
      \verb https://openai.com/blog/function-calling-and-other-api-updates
      \endverb
    \endentry
    \entry{holmLLMsDeathGIS2023}{thesis}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=8f8aaf460591a8f44b3bf1617c246e2d}{%
           family={Holm},
           familyi={H\bibinitperiod},
           given={Oskar},
           giveni={O\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {NTNU}%
      }
      \list{location}{1}{%
        {Trondheim}%
      }
      \strng{namehash}{8f8aaf460591a8f44b3bf1617c246e2d}
      \strng{fullhash}{8f8aaf460591a8f44b3bf1617c246e2d}
      \strng{bibnamehash}{8f8aaf460591a8f44b3bf1617c246e2d}
      \strng{authorbibnamehash}{8f8aaf460591a8f44b3bf1617c246e2d}
      \strng{authornamehash}{8f8aaf460591a8f44b3bf1617c246e2d}
      \strng{authorfullhash}{8f8aaf460591a8f44b3bf1617c246e2d}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The emergence of powerful LLMs with remarkable reasoning and coding capabilities - like GPT-4, the latest additions to the GPT series - enables automation of a wide range of tasks. ChatGPT's Code Interpreter is able to generate, execute, and review its own code, making development of autonomous AI agents far easier than before. This specialization project report explores the feasibility of LLM-based GIS agents, investigating how ChatGPT is currently being used in the field of GIS, how such LLMs could be used if applied in larger systems, and how such systems can be implemented. This report seeks to highlight the strengths of current LLM-based technologies, but also their weaknesses, and suggest areas of improvements and possible solutions to overcome current limitations. These goals are achieved through a literature study and three experiments that aim to support the findings of the literature study. The literature study presents the body of work that has already been done in regard to the position of LLMs in the field of GIS, as well as planning strategies applied in LLM-based agents, and retrieval-augmented generation - that is, giving the LLM hooks into the real world. The three experiments focus on ChatGPT's ability to handle geospatial data in various formats and through different access channels. The overall goal of this specialisation project is to lay the groundwork for development of LLM-based GIS agents.}
      \field{langid}{english}
      \field{month}{12}
      \field{title}{{{LLMs}} - {{The Death}} of {{GIS Analysis}}?}
      \field{type}{Specialization Project}
      \field{year}{2023}
      \verb{urlraw}
      \verb https://github.com/oskarhlm/prosjektoppgave/blob/main/tex/auxiliary/main.pdf
      \endverb
      \verb{url}
      \verb https://github.com/oskarhlm/prosjektoppgave/blob/main/tex/auxiliary/main.pdf
      \endverb
    \endentry
    \entry{openaiIntroducingChatGPT2022}{misc}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=0523b13262b12c215d8009938f5c14f1}{%
           family={{OpenAI}},
           familyi={O\bibinitperiod}}}%
      }
      \strng{namehash}{0523b13262b12c215d8009938f5c14f1}
      \strng{fullhash}{0523b13262b12c215d8009938f5c14f1}
      \strng{bibnamehash}{0523b13262b12c215d8009938f5c14f1}
      \strng{authorbibnamehash}{0523b13262b12c215d8009938f5c14f1}
      \strng{authornamehash}{0523b13262b12c215d8009938f5c14f1}
      \strng{authorfullhash}{0523b13262b12c215d8009938f5c14f1}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We've trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.}
      \field{langid}{american}
      \field{month}{11}
      \field{title}{Introducing {{ChatGPT}}}
      \field{urlday}{26}
      \field{urlmonth}{10}
      \field{urlyear}{2023}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb C:\Users\oskar\Zotero\storage\BXCIMZNC\chatgpt.html
      \endverb
      \verb{urlraw}
      \verb https://openai.com/blog/chatgpt
      \endverb
      \verb{url}
      \verb https://openai.com/blog/chatgpt
      \endverb
    \endentry
    \entry{radfordImprovingLanguageUnderstanding2018}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=a812c46caad94fc8701be37871f303ba}{%
           family={Radford},
           familyi={R\bibinitperiod},
           given={Alec},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=997c3143c2e5d593e816d2ff704fbf98}{%
           family={Narasimhan},
           familyi={N\bibinitperiod},
           given={Karthik},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{93049198c7ea4c7c282daf6e881b2cbc}
      \strng{fullhash}{93049198c7ea4c7c282daf6e881b2cbc}
      \strng{bibnamehash}{93049198c7ea4c7c282daf6e881b2cbc}
      \strng{authorbibnamehash}{93049198c7ea4c7c282daf6e881b2cbc}
      \strng{authornamehash}{93049198c7ea4c7c282daf6e881b2cbc}
      \strng{authorfullhash}{93049198c7ea4c7c282daf6e881b2cbc}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).}
      \field{title}{Improving {{Language Understanding}} by {{Generative Pre-Training}}}
      \field{urlday}{9}
      \field{urlmonth}{10}
      \field{urlyear}{2023}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb C:\Users\oskar\Zotero\storage\HR6GDGYQ\Radford and Narasimhan - 2018 - Improving Language Understanding by Generative Pre.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
      \endverb
      \verb{url}
      \verb https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
      \endverb
    \endentry
    \entry{vaswaniAttentionAllYou2017}{misc}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=7f28e84700536646dd6620a0db07ad09}{%
           family={Vaswani},
           familyi={V\bibinitperiod},
           given={Ashish},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=06649ebab1ea5cac0250746a19764975}{%
           family={Parmar},
           familyi={P\bibinitperiod},
           given={Niki},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2fd2982e30ebcec93ec1cf76e0d797fd}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Llion},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=27b07e4eacbf4ef7a1438e3badb7dd8d}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Aidan\bibnamedelima N.},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2bc899b1160163417da7bf510f15d33}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Lukasz},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=95595a0fefb86187cbc36e551017d332}{%
           family={Polosukhin},
           familyi={P\bibinitperiod},
           given={Illia},
           giveni={I\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{fullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{bibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authorbibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authornamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorfullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.}
      \field{journaltitle}{arXiv.org}
      \field{langid}{english}
      \field{month}{6}
      \field{title}{Attention {{Is All You Need}}}
      \field{urlday}{10}
      \field{urlmonth}{10}
      \field{urlyear}{2023}
      \field{year}{2017}
      \field{urldateera}{ce}
      \verb{file}
      \verb C:\Users\oskar\Zotero\storage\KG8K58TW\Vaswani et al. - 2017 - Attention Is All You Need.pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/1706.03762v7
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/1706.03762v7
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

