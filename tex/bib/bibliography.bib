@misc{longLargeLanguageModel2023,
  title = {Large {{Language Model Guided Tree-of-Thought}}},
  author = {Long, Jieyi},
  year = {2023},
  month = may,
  number = {arXiv:2305.08291},
  eprint = {2305.08291},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2305.08291},
  urldate = {2024-02-12},
  abstract = {In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel approach aimed at improving the problem-solving capabilities of auto-regressive large language models (LLMs). The ToT technique is inspired by the human mind's approach for solving complex reasoning tasks through trial and error. In this process, the human mind explores the solution space through a tree-like thought process, allowing for backtracking when necessary. To implement ToT as a software system, we augment an LLM with additional modules including a prompter agent, a checker module, a memory module, and a ToT controller. In order to solve a given problem, these modules engage in a multi-round conversation with the LLM. The memory module records the conversation and state history of the problem solving process, which allows the system to backtrack to the previous steps of the thought-process and explore other directions from there. To verify the effectiveness of the proposed technique, we implemented a ToT-based solver for the Sudoku Puzzle. Experimental results show that the ToT framework can significantly increase the success rate of Sudoku puzzle solving. Our implementation of the ToT-based Sudoku solver is available on GitHub: {\textbackslash}url\{https://github.com/jieyilong/tree-of-thought-puzzle-solver\}.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\2RDF9TXE\\Long - 2023 - Large Language Model Guided Tree-of-Thought.pdf;C\:\\Users\\oskar\\Zotero\\storage\\TJG6C6J7\\2305.html}
}

@misc{maiOpportunitiesChallengesFoundation2023b,
  title = {On the {{Opportunities}} and {{Challenges}} of {{Foundation Models}} for {{Geospatial Artificial Intelligence}}},
  author = {Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni},
  year = {2023},
  month = apr,
  number = {arXiv:2304.06798},
  eprint = {2304.06798},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2304.06798},
  url = {http://arxiv.org/abs/2304.06798},
  urldate = {2024-01-24},
  abstract = {Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, these task-agnostic LLMs can outperform task-specific fully-supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image-based urban noise intensity classification, and remote sensing image scene classification), existing foundation models still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing a FM for GeoAI is to address the multimodality nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal foundation model which can reason over various types of geospatial data through geospatial alignments. We conclude this paper by discussing the unique risks and challenges to develop such a model for GeoAI.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,I.2.0,I.2.10,I.2.4,I.2.7,I.5.1},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\X82XT37U\\Mai et al. - 2023 - On the Opportunities and Challenges of Foundation .pdf;C\:\\Users\\oskar\\Zotero\\storage\\JUDG2RZS\\2304.html}
}

@misc{rajkumarEvaluatingTexttoSQLCapabilities2022,
  title = {Evaluating the {{Text-to-SQL Capabilities}} of {{Large Language Models}}},
  author = {Rajkumar, Nitarshan and Li, Raymond and Bahdanau, Dzmitry},
  year = {2022},
  month = mar,
  number = {arXiv:2204.00498},
  eprint = {2204.00498},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2204.00498},
  url = {http://arxiv.org/abs/2204.00498},
  urldate = {2024-02-08},
  abstract = {We perform an empirical evaluation of Text-to-SQL capabilities of the Codex language model. We find that, without any finetuning, Codex is a strong baseline on the Spider benchmark; we also analyze the failure modes of Codex in this setting. Furthermore, we demonstrate on the GeoQuery and Scholar benchmarks that a small number of in-domain examples provided in the prompt enables Codex to perform better than state-of-the-art models finetuned on such few-shot examples.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Databases,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\E9NBMPWI\\Rajkumar et al. - 2022 - Evaluating the Text-to-SQL Capabilities of Large L.pdf;C\:\\Users\\oskar\\Zotero\\storage\\HWQVPKL2\\2204.html}
}
