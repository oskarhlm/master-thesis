{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.tools.shell import ShellTool\n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.tools.shell import ShellTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "# If you want to see the prompt in full, you can at: https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You are a helpful GIS agent/consultant.'),\n",
    "        HumanMessagePromptTemplate.from_template('{input}'),\n",
    "        MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "    ]\n",
    ")\n",
    "tools = [PythonREPLTool(), ShellTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0, streaming=True)\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_status = {}\n",
    "# async for chunk in agent_executor.astream_log(\n",
    "#     {\"input\": \"what is the weather in sf\", \"chat_history\": []},\n",
    "#     include_names=[\"ChatOpenAI\"],\n",
    "# ):\n",
    "#     for op in chunk.ops:\n",
    "#         if op[\"op\"] == \"add\":\n",
    "#             if op[\"path\"] not in path_status:\n",
    "#                 path_status[op[\"path\"]] = op[\"value\"]\n",
    "#             else:\n",
    "#                 path_status[op[\"path\"]] += op[\"value\"]\n",
    "#     print(op[\"path\"])\n",
    "#     print(path_status.get(op[\"path\"]))\n",
    "#     print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/master-thesis/src/langchain/langchain-env/lib/python3.11/site-packages/langchain_community/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " ['ls']\n",
      "\n",
      "api_calls.ipynb\n",
      "docs\n",
      "geonorge_custom_chain.ipynb\n",
      "geonorge.ipynb\n",
      "__init__.py\n",
      "lcel_test.ipynb\n",
      "memory.ipynb\n",
      "openapi_test.ipynb\n",
      "pdf_with_embeddings.ipynb\n",
      "query_constructor.ipynb\n",
      "redis.ipynb\n",
      "request_agent.ipynb\n",
      "sql_agent.ipynb\n",
      "token_streaming_test.ipynb\n",
      "tool_agent.ipynb\n",
      "tools\n",
      "wandb\n",
      "wandb.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessageChunk, FunctionMessage, FunctionMessageChunk\n",
    "\n",
    "tool_calls = {}\n",
    "\n",
    "# https://github.com/langchain-ai/langchain/discussions/15755#discussioncomment-8071748\n",
    "# async for chunk in agent_executor.astream_log({\"input\": \"Tell me a story about the user's favorite pet?\"}, include_names=['ChatOpenAI']):\n",
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"List the contents of this folder using both python and bash\"},\n",
    "    include_names=['ChatOpenAI']\n",
    "):\n",
    "    for op in chunk.ops:\n",
    "        print(chunk)\n",
    "        if op['op'] != 'add':\n",
    "            continue\n",
    "\n",
    "        value = op['value']\n",
    "\n",
    "        if isinstance(value, FunctionMessage):\n",
    "            print(value.content)\n",
    "\n",
    "        if not isinstance(value, AIMessageChunk):\n",
    "            continue\n",
    "\n",
    "        if 'tool_calls' in value.additional_kwargs:\n",
    "            tool_call = value.additional_kwargs['tool_calls'][0]\n",
    "            if tool_call['index'] not in tool_calls:\n",
    "                tool_calls[tool_call['index']] = {\n",
    "                    'id': tool_call['id'],\n",
    "                    'name': tool_call['function']['name'],\n",
    "                    'arguments': ''\n",
    "                }\n",
    "                if len(tool_calls.keys()) > 0:\n",
    "                    # print('\\n')\n",
    "                    pass\n",
    "                # print(f'Using tool: {tool_call[\"function\"][\"name\"]}')\n",
    "            else: \n",
    "                tool_calls[tool_call['index']]['arguments'] += tool_call['function']['arguments']\n",
    "                # print(tool_call['function']['arguments'], end='')\n",
    "            continue\n",
    "\n",
    "        # print(value.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"id\": \"call_UWA6oHukbuFSxVkL5RkYlvso\",\n",
      "        \"name\": \"Python_REPL\",\n",
      "        \"arguments\": \"{\\\"__arg1\\\": \\\"import os\\\\nos.listdir()\\\"}\"\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"id\": \"call_Hex17C7t7uB8l8VkYxEXILfm\",\n",
      "        \"name\": \"terminal\",\n",
      "        \"arguments\": \"{\\\"commands\\\": \\\"ls\\\"}\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(tool_calls, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
