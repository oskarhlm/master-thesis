{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection ID: public.5001elveg2.0l\n",
      "Description: Elveg 2.0 - Vegnettsdatasett som omfatter alle kjÃ¸rbare veger som er lengre enn 50 meter, eller del av et nettverk, samt gang- og sykkelveger og sykkelveger representert som veglenkegeometri.\n",
      "Geometry Type: MultiLineString\n",
      "Relevant Properties: [{'name': 'koordh', 'type': 'number', 'description': ''}, {'name': 'fartsgrens', 'type': 'number', 'description': ''}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from geojson_pydantic import FeatureCollection\n",
    "from typing import Any, Sequence, Type\n",
    "import requests\n",
    "from langchain.tools.requests.tool import RequestsGetTool\n",
    "\n",
    "BASE_URL = 'http://localhost:9000'\n",
    "\n",
    "def describe_collection(url: str, relevant_properties: Sequence[str]) -> str:\n",
    "    res = requests.get(url).json()\n",
    "    return (\n",
    "        f\"Collection ID: {res['id']}\\n\"\n",
    "        f\"Description: {res['description']}\\n\"\n",
    "        f\"Geometry Type: {res['geometrytype']}\\n\"\n",
    "        f\"Relevant Properties: {[prop for prop in res['properties'] if prop['name'] in relevant_properties or len(prop) == 0]}\\n\"\n",
    "    )\n",
    "\n",
    "print(describe_collection(\n",
    "    'http://localhost:9000/collections/public.5001elveg2.0l.json', ['koordh', 'fartsgrens']))\n",
    "\n",
    "class RelevantCollectionProperties(BaseModel):\n",
    "    collection_id: str = Field(..., description='ID of the collection')\n",
    "    relevant_properties: Sequence[str] = Field(..., description=\"Properties in the collection that can be used to answer the user's query\")\n",
    "\n",
    "class RelevantCollectionsAndPropertiesInput(BaseModel):\n",
    "    collections_with_props: Sequence[RelevantCollectionProperties]\n",
    "\n",
    "class RelevantCollectionsAndPropertiesTool(BaseTool):\n",
    "    name: str = 'relevant_collections_and_properties'\n",
    "    args_schema: Type[BaseModel] = RelevantCollectionsAndPropertiesInput\n",
    "    description: str = 'Use this to get a concise textual description of relevant collections and properties within these.'\n",
    "\n",
    "    def _run(self, collections_with_props: Sequence[RelevantCollectionProperties], *args: Any, **kwargs: Any) -> Any:\n",
    "        return [describe_collection(f'{BASE_URL}/collections/{cwp.collection_id}', cwp.relevant_properties) for cwp in collections_with_props]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chain.invoke() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 50\u001b[0m\n\u001b[1;32m     42\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_openai_tools_agent(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt, tools\u001b[38;5;241m=\u001b[39mtools)\n\u001b[1;32m     44\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(\n\u001b[1;32m     45\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m     46\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m     47\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# res = agent_executor.invoke(\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#     {'user_query': 'Get me the road segments of the noisiest roads in Trondheim.'})\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Chain.invoke() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain_core.messages import AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain.tools.requests.tool import RequestsGetTool\n",
    "from langchain.requests import RequestsWrapper\n",
    "\n",
    "load_dotenv('../../../.env')\n",
    "\n",
    "system_message = \"\"\"Create a computational graph for a GIS-related question.\n",
    "All operation nodes should be followed by an intermediary node.\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0)\n",
    "\n",
    "# I should then go to http://localhost:9000/collections/{collection_id} to see which properties are relevant. \n",
    "AI_SUFFIX = \"\"\"I should look through ALL collections available at http://localhost:9000/collections to see which are usable for the problem at hand.\n",
    "I should then get a concise description of these collections and the relevant properties of these. \n",
    "\n",
    "Here is the query from the user: \n",
    "{user_query}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=system_message),\n",
    "        AIMessage(content=AI_SUFFIX),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt.partial(\n",
    "    user_query='Get me the road segments of the noisiest roads in Trondheim.')\n",
    "\n",
    "tools = [RelevantCollectionsAndPropertiesTool(), RequestsGetTool(\n",
    "    requests_wrapper=RequestsWrapper())]\n",
    "\n",
    "agent = create_openai_tools_agent(llm=llm, prompt=prompt, tools=tools)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "res = agent_executor.invoke()\n",
    "\n",
    "# res = agent_executor.invoke(\n",
    "#     {'user_query': 'Get me the road segments of the noisiest roads in Trondheim.'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
